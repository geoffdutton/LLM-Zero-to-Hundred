{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "import pandas as pd\n",
    "from pyprojroot import here\n",
    "from collections import Counter\n",
    "import os\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(here(\"configs/config.yml\")) as cfg:\n",
    "    cfg = yaml.load(cfg, Loader=yaml.FullLoader)\n",
    "questions_df = pd.read_excel(\n",
    "    os.path.join(here(cfg[\"eval_questions_dir\"]), cfg[\"eval_file_name\"])\n",
    ")\n",
    "final_df = pd.DataFrame(columns=[\"best_scorer\", \"num_top_appearance\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check for Nan values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Index([], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "print(questions_df[\"langchain_token_mmr_score\"].isna().sum())\n",
    "print(questions_df[questions_df[\"langchain_token_mmr_score\"].isna()].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['source', 'question', 'correct_answer', 'langchain_token_mmr_result',\n",
       "       'langchain_token_mmr_inference_time',\n",
       "       'langchain_recursive_similarity_result',\n",
       "       'langchain_recursive_similarity_inference_time',\n",
       "       'langchain_recursive_mmr_result',\n",
       "       'langchain_recursive_mmr_inference_time',\n",
       "       'llama_index_sentence_retrieval_result',\n",
       "       'llama_index_sentence_retrieval_inference_time',\n",
       "       'llama_index_auto_merging_retrieval_result',\n",
       "       'llama_index_auto_merging_retrieval_inference_time',\n",
       "       'langchain_recursive_similarity_score', 'langchain_recursive_mmr_score',\n",
       "       'llama_index_sentence_retrieval_score',\n",
       "       'llama_index_auto_merging_retrieval_score', 'lowest_score',\n",
       "       'highest_score', 'langchain_token_mmr_score',\n",
       "       'langchain_token_mmr_result_score', 'langchain_token_mmr_score_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute and print total scores (from 40):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total scores:\n",
      "    langchain_token_mmr_total_score: 32.6, \n",
      "    langchain_similarity_total_score: 35.9,\n",
      "    langchain_recursive_mmr_total_score: 32.0,\n",
      "    llama_index_sentence_retrieval_score: 34.9,\n",
      "    llama_index_auto_merging_retrieval_total_score: 29.8\n"
     ]
    }
   ],
   "source": [
    "langchain_token_mmr_total_score = sum(questions_df[\"langchain_token_mmr_score\"])\n",
    "langchain_similarity_total_score = sum(\n",
    "    questions_df[\"langchain_recursive_similarity_score\"]\n",
    ")\n",
    "langchain_recursive_mmr_total_score = sum(questions_df[\"langchain_recursive_mmr_score\"])\n",
    "llama_index_sentence_retrieval_score = sum(\n",
    "    questions_df[\"llama_index_sentence_retrieval_score\"]\n",
    ")\n",
    "llama_index_auto_merging_retrieval_total_score = sum(\n",
    "    questions_df[\"llama_index_auto_merging_retrieval_score\"]\n",
    ")\n",
    "print(\n",
    "    f\"Total scores:\\n\\\n",
    "    langchain_token_mmr_total_score: {round(langchain_token_mmr_total_score, 2)}, \\n\\\n",
    "    langchain_similarity_total_score: {round(langchain_similarity_total_score, 2)},\\n\\\n",
    "    langchain_recursive_mmr_total_score: {round(langchain_recursive_mmr_total_score, 2)},\\n\\\n",
    "    llama_index_sentence_retrieval_score: {round(llama_index_sentence_retrieval_score, 2)},\\n\\\n",
    "    llama_index_auto_merging_retrieval_total_score: {round(llama_index_auto_merging_retrieval_total_score, 2)}\"\n",
    ")\n",
    "scorer_list = [\n",
    "    langchain_token_mmr_total_score,\n",
    "    langchain_similarity_total_score,\n",
    "    langchain_recursive_mmr_total_score,\n",
    "    llama_index_sentence_retrieval_score,\n",
    "    llama_index_auto_merging_retrieval_total_score,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Best overall performance:   langchain_recursive_similarity\n",
    "* Wrost overall performance: llama_index_auto_merging_retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[\"best_scorer\"] = scorer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32.59999999999999,\n",
       " 35.89999999999997,\n",
       " 32.000000000000014,\n",
       " 34.89999999999998,\n",
       " 29.8]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scorer_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  langchain_token_mmr: 32.6,\n",
    "#     langchain_recursive_similarity: 35.9,\n",
    "#     langchain_recursive_mmr: 32.0,\n",
    "#     llama_index_sentence_retrieval: 34.9,\n",
    "#     llama_index_auto_merging_retrieval: 29.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain_token_mmr_total_score: 32.6,\n",
    "# langchain_similarity_total_score: 35.9,\n",
    "# langchain_mmr_total_score: 32.0,\n",
    "# llama_index_sentence_retrieval_score: 34.9,\n",
    "# llama_index_auto_merging_retrieval_total_score: 29.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = questions_df[\n",
    "    [\n",
    "        \"langchain_token_mmr_score\",\n",
    "        \"langchain_recursive_similarity_score\",\n",
    "        \"langchain_recursive_mmr_score\",\n",
    "        \"llama_index_sentence_retrieval_score\",\n",
    "        \"llama_index_auto_merging_retrieval_score\",\n",
    "    ]\n",
    "]\n",
    "max_cols = score_df.apply(lambda x: x[x == x.max()].index.tolist(), axis=1)\n",
    "max_cols_list = max_cols.to_list()\n",
    "\n",
    "min_cols = score_df.apply(lambda x: x[x == x.min()].index.tolist(), axis=1)\n",
    "min_cols_list = min_cols.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Count the number of times that each technique was among the highest scorers:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of times each column name appears in the top scorer list\n",
    "max_cols_count = Counter([col for row in max_cols_list for col in row])\n",
    "max_cols_count\n",
    "top_appearance_list = list(max_cols_count.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'llama_index_sentence_retrieval_score': 35,\n",
       "         'langchain_recursive_similarity_score': 32,\n",
       "         'langchain_token_mmr_score': 23,\n",
       "         'langchain_recursive_mmr_score': 9,\n",
       "         'llama_index_auto_merging_retrieval_score': 8})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_cols_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_scorer</th>\n",
       "      <th>num_top_appearance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   best_scorer num_top_appearance\n",
       "0         32.6                NaN\n",
       "1         35.9                NaN\n",
       "2         32.0                NaN\n",
       "3         34.9                NaN\n",
       "4         29.8                NaN"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.index = [\n",
    "    \"langchain_token_mmr\",\n",
    "    \"langchain_recursive_similarity\",\n",
    "    \"langchain_recursive_mmr\",\n",
    "    \"llama_index_sentence_retrieval\",\n",
    "    \"llama_index_auto_merging_retrieval\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in final_df.iterrows():\n",
    "    final_df.at[idx, \"num_top_appearance\"] = int(max_cols_count[f\"{idx}_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_scorer</th>\n",
       "      <th>num_top_appearance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>langchain_token_mmr</th>\n",
       "      <td>32.6</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>langchain_recursive_similarity</th>\n",
       "      <td>35.9</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>langchain_recursive_mmr</th>\n",
       "      <td>32.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_index_sentence_retrieval</th>\n",
       "      <td>34.9</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_index_auto_merging_retrieval</th>\n",
       "      <td>29.8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    best_scorer num_top_appearance\n",
       "langchain_token_mmr                        32.6                 23\n",
       "langchain_recursive_similarity             35.9                 32\n",
       "langchain_recursive_mmr                    32.0                  9\n",
       "llama_index_sentence_retrieval             34.9                 35\n",
       "llama_index_auto_merging_retrieval         29.8                  8"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Count the number of times that each technique was among the lowest scorers:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'llama_index_auto_merging_retrieval_score': 30,\n",
       "         'langchain_recursive_mmr_score': 21,\n",
       "         'langchain_token_mmr_score': 11,\n",
       "         'langchain_recursive_similarity_score': 6,\n",
       "         'llama_index_sentence_retrieval_score': 6})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of times each column name appears in the lowest scorer list\n",
    "min_cols_count = Counter([col for row in min_cols_list for col in row])\n",
    "min_cols_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total zero scores:\n",
      "    langchain_token_mmr: 2,\n",
      "    langchain_recursive_similarity: 0,\n",
      "    langchain_recursive_mmr: 0,\n",
      "    llama_index_sentence_retrieval: 0,\n",
      "    llama_index_auto_merging_retrieval: 1\n"
     ]
    }
   ],
   "source": [
    "def count_number_of_zero_scores(df, column_name):\n",
    "    return len(df[df[column_name] == 0])\n",
    "\n",
    "\n",
    "langchain_token_mmr_total_zero_score = count_number_of_zero_scores(\n",
    "    questions_df, \"langchain_token_mmr_score\"\n",
    ")\n",
    "langchain_recursive_similarity_total_zero_score = count_number_of_zero_scores(\n",
    "    questions_df, \"langchain_recursive_similarity_score\"\n",
    ")\n",
    "langchain_recursive_mmr_total_zero_score = count_number_of_zero_scores(\n",
    "    questions_df, \"langchain_recursive_mmr_score\"\n",
    ")\n",
    "llama_index_sentence_retrieval_zero_score = count_number_of_zero_scores(\n",
    "    questions_df, \"llama_index_sentence_retrieval_score\"\n",
    ")\n",
    "llama_index_auto_merging_retrieval_total_zero_score = count_number_of_zero_scores(\n",
    "    questions_df, \"llama_index_auto_merging_retrieval_score\"\n",
    ")\n",
    "print(\n",
    "    f\"Total zero scores:\\n\\\n",
    "    langchain_token_mmr: {langchain_token_mmr_total_zero_score},\\n\\\n",
    "    langchain_recursive_similarity: {langchain_recursive_similarity_total_zero_score},\\n\\\n",
    "    langchain_recursive_mmr: {langchain_recursive_mmr_total_zero_score},\\n\\\n",
    "    llama_index_sentence_retrieval: {llama_index_sentence_retrieval_zero_score},\\n\\\n",
    "    llama_index_auto_merging_retrieval: {llama_index_auto_merging_retrieval_total_zero_score}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis based on each document**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>langchain_token_mmr_score</th>\n",
       "      <th>langchain_recursive_similarity_score</th>\n",
       "      <th>langchain_recursive_mmr_score</th>\n",
       "      <th>llama_index_sentence_retrieval_score</th>\n",
       "      <th>llama_index_auto_merging_retrieval_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SegmentAnything paper</th>\n",
       "      <td>11.6</td>\n",
       "      <td>12.5</td>\n",
       "      <td>10.4</td>\n",
       "      <td>12.1</td>\n",
       "      <td>10.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product scpecification</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stories</th>\n",
       "      <td>4.1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>technical support</th>\n",
       "      <td>4.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vision transformer paper</th>\n",
       "      <td>9.1</td>\n",
       "      <td>9.9</td>\n",
       "      <td>8.8</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          langchain_token_mmr_score  \\\n",
       "source                                                \n",
       "SegmentAnything paper                          11.6   \n",
       "product scpecification                          3.0   \n",
       "stories                                         4.1   \n",
       "technical support                               4.8   \n",
       "vision transformer paper                        9.1   \n",
       "\n",
       "                          langchain_recursive_similarity_score  \\\n",
       "source                                                           \n",
       "SegmentAnything paper                                     12.5   \n",
       "product scpecification                                     4.1   \n",
       "stories                                                    4.5   \n",
       "technical support                                          4.9   \n",
       "vision transformer paper                                   9.9   \n",
       "\n",
       "                          langchain_recursive_mmr_score  \\\n",
       "source                                                    \n",
       "SegmentAnything paper                              10.4   \n",
       "product scpecification                              3.9   \n",
       "stories                                             4.0   \n",
       "technical support                                   4.9   \n",
       "vision transformer paper                            8.8   \n",
       "\n",
       "                          llama_index_sentence_retrieval_score  \\\n",
       "source                                                           \n",
       "SegmentAnything paper                                     12.1   \n",
       "product scpecification                                     4.2   \n",
       "stories                                                    4.5   \n",
       "technical support                                          4.1   \n",
       "vision transformer paper                                  10.0   \n",
       "\n",
       "                          llama_index_auto_merging_retrieval_score  \n",
       "source                                                              \n",
       "SegmentAnything paper                                         10.1  \n",
       "product scpecification                                         4.0  \n",
       "stories                                                        3.3  \n",
       "technical support                                              4.6  \n",
       "vision transformer paper                                       7.8  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "langchain_token_mmr_df = questions_df.pivot_table(\n",
    "    index=\"source\", columns=None, values=\"langchain_token_mmr_score\", aggfunc=\"sum\"\n",
    ")\n",
    "langchain_recursive_similarity_df = questions_df.pivot_table(\n",
    "    index=\"source\",\n",
    "    columns=None,\n",
    "    values=\"langchain_recursive_similarity_score\",\n",
    "    aggfunc=\"sum\",\n",
    ")\n",
    "langchain_recursive_mmr_df = questions_df.pivot_table(\n",
    "    index=\"source\", columns=None, values=\"langchain_recursive_mmr_score\", aggfunc=\"sum\"\n",
    ")\n",
    "llama_index_sentence_df = questions_df.pivot_table(\n",
    "    index=\"source\",\n",
    "    columns=None,\n",
    "    values=\"llama_index_sentence_retrieval_score\",\n",
    "    aggfunc=\"sum\",\n",
    ")\n",
    "llama_index_auto_merging_df = questions_df.pivot_table(\n",
    "    index=\"source\",\n",
    "    columns=None,\n",
    "    values=\"llama_index_auto_merging_retrieval_score\",\n",
    "    aggfunc=\"sum\",\n",
    ")\n",
    "\n",
    "# Concatenate the DataFrames into a single DataFrame\n",
    "result_df = pd.concat(\n",
    "    [\n",
    "        langchain_token_mmr_df,\n",
    "        langchain_recursive_similarity_df,\n",
    "        langchain_recursive_mmr_df,\n",
    "        llama_index_sentence_df,\n",
    "        llama_index_auto_merging_df,\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# Rename the columns to match your desired output\n",
    "result_df.columns = [\n",
    "    \"langchain_token_mmr_score\",\n",
    "    \"langchain_recursive_similarity_score\",\n",
    "    \"langchain_recursive_mmr_score\",\n",
    "    \"llama_index_sentence_retrieval_score\",\n",
    "    \"llama_index_auto_merging_retrieval_score\",\n",
    "]\n",
    "\n",
    "# Display the result\n",
    "display(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Average score per document (normalized)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized average score per document:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.81, 0.77, 0.82, 0.93, 0.83]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Normalized average score per document:\")\n",
    "num_questions = (\n",
    "    questions_df[[\"source\", \"question\"]].groupby(\"source\").count().values.tolist()\n",
    ")\n",
    "num_questions = [val for sublist in num_questions for val in sublist]\n",
    "mean_doc_score = result_df.mean(axis=1).values.tolist()\n",
    "result = [round(x / y, 2) for x, y in zip(mean_doc_score, num_questions)]\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SegmentAnything paper: (2 column scientific paper) \n",
    "    - Best scorer: \n",
    "    - Wrost scorer:\n",
    "    - Normalized average score:\n",
    "* product scpecification:\n",
    "    - Best scorer: \n",
    "    - Wrost scorer:\n",
    "    - Normalized average score:\n",
    "* stories:\n",
    "    - Best scorer: \n",
    "    - Wrost scorer:\n",
    "    - Normalized average score:\n",
    "* technical support:\n",
    "    - Best scorer: \n",
    "    - Wrost scorer:\n",
    "    - Normalized average score:\n",
    "* vision transformer paper: (1 coulmn scientific paper)\n",
    "    - Best scorer: \n",
    "    - Wrost scorer:\n",
    "    - Normalized average score:\n",
    "-----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Total inference time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_token_mmr_inference_time                    68.97\n",
       "langchain_recursive_mmr_inference_time                62.03\n",
       "langchain_recursive_similarity_inference_time         66.92\n",
       "llama_index_sentence_retrieval_inference_time        100.95\n",
       "llama_index_auto_merging_retrieval_inference_time     52.66\n",
       "dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_df[\n",
    "    [\n",
    "        \"langchain_token_mmr_inference_time\",\n",
    "        \"langchain_recursive_mmr_inference_time\",\n",
    "        \"langchain_recursive_similarity_inference_time\",\n",
    "        \"llama_index_sentence_retrieval_inference_time\",\n",
    "        \"llama_index_auto_merging_retrieval_inference_time\",\n",
    "    ]\n",
    "].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Average inference time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_token_mmr_inference_time                   1.72425\n",
       "langchain_recursive_mmr_inference_time               1.55075\n",
       "langchain_recursive_similarity_inference_time        1.67300\n",
       "llama_index_sentence_retrieval_inference_time        2.52375\n",
       "llama_index_auto_merging_retrieval_inference_time    1.31650\n",
       "dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_df[\n",
    "    [\n",
    "        \"langchain_token_mmr_inference_time\",\n",
    "        \"langchain_recursive_mmr_inference_time\",\n",
    "        \"langchain_recursive_similarity_inference_time\",\n",
    "        \"llama_index_sentence_retrieval_inference_time\",\n",
    "        \"llama_index_auto_merging_retrieval_inference_time\",\n",
    "    ]\n",
    "].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Fastest: llama_index_auto_merging_retrieval_inference_time\n",
    "* slowest: llama_index_sentence_retrieval_inference_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check the zero scored questions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama_index_auto_merging_retrieval:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>question</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>langchain_token_mmr_result</th>\n",
       "      <th>langchain_token_mmr_inference_time</th>\n",
       "      <th>langchain_recursive_similarity_result</th>\n",
       "      <th>langchain_recursive_similarity_inference_time</th>\n",
       "      <th>langchain_recursive_mmr_result</th>\n",
       "      <th>langchain_recursive_mmr_inference_time</th>\n",
       "      <th>llama_index_sentence_retrieval_result</th>\n",
       "      <th>...</th>\n",
       "      <th>llama_index_auto_merging_retrieval_inference_time</th>\n",
       "      <th>langchain_recursive_similarity_score</th>\n",
       "      <th>langchain_recursive_mmr_score</th>\n",
       "      <th>llama_index_sentence_retrieval_score</th>\n",
       "      <th>llama_index_auto_merging_retrieval_score</th>\n",
       "      <th>lowest_score</th>\n",
       "      <th>highest_score</th>\n",
       "      <th>langchain_token_mmr_score</th>\n",
       "      <th>langchain_token_mmr_result_score</th>\n",
       "      <th>langchain_token_mmr_score_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>product scpecification</td>\n",
       "      <td>How much does CubeTriangle Kappa Portable Spea...</td>\n",
       "      <td>2000</td>\n",
       "      <td>The CubeTriangle Kappa Portable Speaker costs ...</td>\n",
       "      <td>0.43</td>\n",
       "      <td>The CubeTriangle Kappa Portable Speaker is pri...</td>\n",
       "      <td>0.36</td>\n",
       "      <td>The CubeTriangle Kappa Portable Speaker is pri...</td>\n",
       "      <td>0.46</td>\n",
       "      <td>Based on the given context information, the pr...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>langchain_token_mmr</td>\n",
       "      <td>langchain_token_mmr</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    source                                           question  \\\n",
       "13  product scpecification  How much does CubeTriangle Kappa Portable Spea...   \n",
       "\n",
       "   correct_answer                         langchain_token_mmr_result  \\\n",
       "13           2000  The CubeTriangle Kappa Portable Speaker costs ...   \n",
       "\n",
       "    langchain_token_mmr_inference_time  \\\n",
       "13                                0.43   \n",
       "\n",
       "                langchain_recursive_similarity_result  \\\n",
       "13  The CubeTriangle Kappa Portable Speaker is pri...   \n",
       "\n",
       "    langchain_recursive_similarity_inference_time  \\\n",
       "13                                           0.36   \n",
       "\n",
       "                       langchain_recursive_mmr_result  \\\n",
       "13  The CubeTriangle Kappa Portable Speaker is pri...   \n",
       "\n",
       "    langchain_recursive_mmr_inference_time  \\\n",
       "13                                    0.46   \n",
       "\n",
       "                llama_index_sentence_retrieval_result  ...  \\\n",
       "13  Based on the given context information, the pr...  ...   \n",
       "\n",
       "    llama_index_auto_merging_retrieval_inference_time  \\\n",
       "13                                               0.82   \n",
       "\n",
       "   langchain_recursive_similarity_score  langchain_recursive_mmr_score  \\\n",
       "13                                  0.2                            0.3   \n",
       "\n",
       "    llama_index_sentence_retrieval_score  \\\n",
       "13                                   0.2   \n",
       "\n",
       "    llama_index_auto_merging_retrieval_score         lowest_score  \\\n",
       "13                                       0.0  langchain_token_mmr   \n",
       "\n",
       "          highest_score langchain_token_mmr_score  \\\n",
       "13  langchain_token_mmr                       0.0   \n",
       "\n",
       "   langchain_token_mmr_result_score  langchain_token_mmr_score_score  \n",
       "13                              0.6                              NaN  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama_index_sentence_retrieval:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>question</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>langchain_token_mmr_result</th>\n",
       "      <th>langchain_token_mmr_inference_time</th>\n",
       "      <th>langchain_recursive_similarity_result</th>\n",
       "      <th>langchain_recursive_similarity_inference_time</th>\n",
       "      <th>langchain_recursive_mmr_result</th>\n",
       "      <th>langchain_recursive_mmr_inference_time</th>\n",
       "      <th>llama_index_sentence_retrieval_result</th>\n",
       "      <th>...</th>\n",
       "      <th>llama_index_auto_merging_retrieval_inference_time</th>\n",
       "      <th>langchain_recursive_similarity_score</th>\n",
       "      <th>langchain_recursive_mmr_score</th>\n",
       "      <th>llama_index_sentence_retrieval_score</th>\n",
       "      <th>llama_index_auto_merging_retrieval_score</th>\n",
       "      <th>lowest_score</th>\n",
       "      <th>highest_score</th>\n",
       "      <th>langchain_token_mmr_score</th>\n",
       "      <th>langchain_token_mmr_result_score</th>\n",
       "      <th>langchain_token_mmr_score_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [source, question, correct_answer, langchain_token_mmr_result, langchain_token_mmr_inference_time, langchain_recursive_similarity_result, langchain_recursive_similarity_inference_time, langchain_recursive_mmr_result, langchain_recursive_mmr_inference_time, llama_index_sentence_retrieval_result, llama_index_sentence_retrieval_inference_time, llama_index_auto_merging_retrieval_result, llama_index_auto_merging_retrieval_inference_time, langchain_recursive_similarity_score, langchain_recursive_mmr_score, llama_index_sentence_retrieval_score, llama_index_auto_merging_retrieval_score, lowest_score, highest_score, langchain_token_mmr_score, langchain_token_mmr_result_score, langchain_token_mmr_score_score]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain_token_mmr:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>question</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>langchain_token_mmr_result</th>\n",
       "      <th>langchain_token_mmr_inference_time</th>\n",
       "      <th>langchain_recursive_similarity_result</th>\n",
       "      <th>langchain_recursive_similarity_inference_time</th>\n",
       "      <th>langchain_recursive_mmr_result</th>\n",
       "      <th>langchain_recursive_mmr_inference_time</th>\n",
       "      <th>llama_index_sentence_retrieval_result</th>\n",
       "      <th>...</th>\n",
       "      <th>llama_index_auto_merging_retrieval_inference_time</th>\n",
       "      <th>langchain_recursive_similarity_score</th>\n",
       "      <th>langchain_recursive_mmr_score</th>\n",
       "      <th>llama_index_sentence_retrieval_score</th>\n",
       "      <th>llama_index_auto_merging_retrieval_score</th>\n",
       "      <th>lowest_score</th>\n",
       "      <th>highest_score</th>\n",
       "      <th>langchain_token_mmr_score</th>\n",
       "      <th>langchain_token_mmr_result_score</th>\n",
       "      <th>langchain_token_mmr_score_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>product scpecification</td>\n",
       "      <td>How much does CubeTriangle Kappa Portable Spea...</td>\n",
       "      <td>2000</td>\n",
       "      <td>The CubeTriangle Kappa Portable Speaker costs ...</td>\n",
       "      <td>0.43</td>\n",
       "      <td>The CubeTriangle Kappa Portable Speaker is pri...</td>\n",
       "      <td>0.36</td>\n",
       "      <td>The CubeTriangle Kappa Portable Speaker is pri...</td>\n",
       "      <td>0.46</td>\n",
       "      <td>Based on the given context information, the pr...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>langchain_token_mmr</td>\n",
       "      <td>langchain_token_mmr</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>product scpecification</td>\n",
       "      <td>Is there any skateboard with 20 mph top speed ...</td>\n",
       "      <td>Yes the CubeTriangle Chi Electric Skateboard h...</td>\n",
       "      <td>I'm sorry, but I couldn't find any information...</td>\n",
       "      <td>0.69</td>\n",
       "      <td>Yes, the CubeTriangle Chi Electric Skateboard ...</td>\n",
       "      <td>0.42</td>\n",
       "      <td>Based on the information from the vectorDB, th...</td>\n",
       "      <td>0.98</td>\n",
       "      <td>Yes, there is a skateboard with a 20 mph top s...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>langchain_token_mmr</td>\n",
       "      <td>langchain_token_mmr</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    source                                           question  \\\n",
       "13  product scpecification  How much does CubeTriangle Kappa Portable Spea...   \n",
       "14  product scpecification  Is there any skateboard with 20 mph top speed ...   \n",
       "\n",
       "                                       correct_answer  \\\n",
       "13                                               2000   \n",
       "14  Yes the CubeTriangle Chi Electric Skateboard h...   \n",
       "\n",
       "                           langchain_token_mmr_result  \\\n",
       "13  The CubeTriangle Kappa Portable Speaker costs ...   \n",
       "14  I'm sorry, but I couldn't find any information...   \n",
       "\n",
       "    langchain_token_mmr_inference_time  \\\n",
       "13                                0.43   \n",
       "14                                0.69   \n",
       "\n",
       "                langchain_recursive_similarity_result  \\\n",
       "13  The CubeTriangle Kappa Portable Speaker is pri...   \n",
       "14  Yes, the CubeTriangle Chi Electric Skateboard ...   \n",
       "\n",
       "    langchain_recursive_similarity_inference_time  \\\n",
       "13                                           0.36   \n",
       "14                                           0.42   \n",
       "\n",
       "                       langchain_recursive_mmr_result  \\\n",
       "13  The CubeTriangle Kappa Portable Speaker is pri...   \n",
       "14  Based on the information from the vectorDB, th...   \n",
       "\n",
       "    langchain_recursive_mmr_inference_time  \\\n",
       "13                                    0.46   \n",
       "14                                    0.98   \n",
       "\n",
       "                llama_index_sentence_retrieval_result  ...  \\\n",
       "13  Based on the given context information, the pr...  ...   \n",
       "14  Yes, there is a skateboard with a 20 mph top s...  ...   \n",
       "\n",
       "    llama_index_auto_merging_retrieval_inference_time  \\\n",
       "13                                               0.82   \n",
       "14                                               0.96   \n",
       "\n",
       "   langchain_recursive_similarity_score  langchain_recursive_mmr_score  \\\n",
       "13                                  0.2                            0.3   \n",
       "14                                  0.9                            0.6   \n",
       "\n",
       "    llama_index_sentence_retrieval_score  \\\n",
       "13                                   0.2   \n",
       "14                                   1.0   \n",
       "\n",
       "    llama_index_auto_merging_retrieval_score         lowest_score  \\\n",
       "13                                       0.0  langchain_token_mmr   \n",
       "14                                       1.0  langchain_token_mmr   \n",
       "\n",
       "          highest_score langchain_token_mmr_score  \\\n",
       "13  langchain_token_mmr                       0.0   \n",
       "14  langchain_token_mmr                       0.0   \n",
       "\n",
       "   langchain_token_mmr_result_score  langchain_token_mmr_score_score  \n",
       "13                              0.6                              NaN  \n",
       "14                              0.2                              NaN  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain_recursive_mmr:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>question</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>langchain_token_mmr_result</th>\n",
       "      <th>langchain_token_mmr_inference_time</th>\n",
       "      <th>langchain_recursive_similarity_result</th>\n",
       "      <th>langchain_recursive_similarity_inference_time</th>\n",
       "      <th>langchain_recursive_mmr_result</th>\n",
       "      <th>langchain_recursive_mmr_inference_time</th>\n",
       "      <th>llama_index_sentence_retrieval_result</th>\n",
       "      <th>...</th>\n",
       "      <th>llama_index_auto_merging_retrieval_inference_time</th>\n",
       "      <th>langchain_recursive_similarity_score</th>\n",
       "      <th>langchain_recursive_mmr_score</th>\n",
       "      <th>llama_index_sentence_retrieval_score</th>\n",
       "      <th>llama_index_auto_merging_retrieval_score</th>\n",
       "      <th>lowest_score</th>\n",
       "      <th>highest_score</th>\n",
       "      <th>langchain_token_mmr_score</th>\n",
       "      <th>langchain_token_mmr_result_score</th>\n",
       "      <th>langchain_token_mmr_score_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [source, question, correct_answer, langchain_token_mmr_result, langchain_token_mmr_inference_time, langchain_recursive_similarity_result, langchain_recursive_similarity_inference_time, langchain_recursive_mmr_result, langchain_recursive_mmr_inference_time, llama_index_sentence_retrieval_result, llama_index_sentence_retrieval_inference_time, llama_index_auto_merging_retrieval_result, llama_index_auto_merging_retrieval_inference_time, langchain_recursive_similarity_score, langchain_recursive_mmr_score, llama_index_sentence_retrieval_score, llama_index_auto_merging_retrieval_score, lowest_score, highest_score, langchain_token_mmr_score, langchain_token_mmr_result_score, langchain_token_mmr_score_score]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain_recursive_similarity:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>question</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>langchain_token_mmr_result</th>\n",
       "      <th>langchain_token_mmr_inference_time</th>\n",
       "      <th>langchain_recursive_similarity_result</th>\n",
       "      <th>langchain_recursive_similarity_inference_time</th>\n",
       "      <th>langchain_recursive_mmr_result</th>\n",
       "      <th>langchain_recursive_mmr_inference_time</th>\n",
       "      <th>llama_index_sentence_retrieval_result</th>\n",
       "      <th>...</th>\n",
       "      <th>llama_index_auto_merging_retrieval_inference_time</th>\n",
       "      <th>langchain_recursive_similarity_score</th>\n",
       "      <th>langchain_recursive_mmr_score</th>\n",
       "      <th>llama_index_sentence_retrieval_score</th>\n",
       "      <th>llama_index_auto_merging_retrieval_score</th>\n",
       "      <th>lowest_score</th>\n",
       "      <th>highest_score</th>\n",
       "      <th>langchain_token_mmr_score</th>\n",
       "      <th>langchain_token_mmr_result_score</th>\n",
       "      <th>langchain_token_mmr_score_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [source, question, correct_answer, langchain_token_mmr_result, langchain_token_mmr_inference_time, langchain_recursive_similarity_result, langchain_recursive_similarity_inference_time, langchain_recursive_mmr_result, langchain_recursive_mmr_inference_time, llama_index_sentence_retrieval_result, llama_index_sentence_retrieval_inference_time, llama_index_auto_merging_retrieval_result, llama_index_auto_merging_retrieval_inference_time, langchain_recursive_similarity_score, langchain_recursive_mmr_score, llama_index_sentence_retrieval_score, llama_index_auto_merging_retrieval_score, lowest_score, highest_score, langchain_token_mmr_score, langchain_token_mmr_result_score, langchain_token_mmr_score_score]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"llama_index_auto_merging_retrieval:\")\n",
    "display(questions_df[questions_df[\"llama_index_auto_merging_retrieval_score\"] == 0])\n",
    "print(\"llama_index_sentence_retrieval:\")\n",
    "display(questions_df[questions_df[\"llama_index_sentence_retrieval_score\"] == 0])\n",
    "print(\"langchain_token_mmr:\")\n",
    "display(questions_df[questions_df[\"langchain_token_mmr_score\"] == 0])\n",
    "print(\"langchain_recursive_mmr:\")\n",
    "display(questions_df[questions_df[\"langchain_recursive_mmr_score\"] == 0])\n",
    "print(\"langchain_recursive_similarity:\")\n",
    "display(questions_df[questions_df[\"langchain_recursive_similarity_score\"] == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in [0, 38, 13, 30, 13]:\n",
    "#     print(questions_df[questions_df.index==i][\"question\"].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.reset_index().rename(columns={\"index\": \"method\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[\"num_top_appearance\"] = final_df[\"num_top_appearance\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "<b>%{hovertext}</b><br><br>method=%{x}<br>best_scorer=%{y}<br>num_top_appearance=%{marker.size}<extra></extra>",
         "hovertext": [
          "langchain_token_mmr"
         ],
         "legendgroup": "langchain_token_mmr",
         "marker": {
          "color": "#636EFA",
          "line": {
           "color": "darkgrey",
           "width": 3
          },
          "size": [
           23
          ],
          "sizemode": "area",
          "sizeref": 0.0875,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "langchain_token_mmr",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "langchain_token_mmr"
         ],
         "xaxis": "x",
         "y": [
          32.59999999999999
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "<b>%{hovertext}</b><br><br>method=%{x}<br>best_scorer=%{y}<br>num_top_appearance=%{marker.size}<extra></extra>",
         "hovertext": [
          "langchain_recursive_similarity"
         ],
         "legendgroup": "langchain_recursive_similarity",
         "marker": {
          "color": "#EF553B",
          "line": {
           "color": "darkgrey",
           "width": 3
          },
          "size": [
           32
          ],
          "sizemode": "area",
          "sizeref": 0.0875,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "langchain_recursive_similarity",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "langchain_recursive_similarity"
         ],
         "xaxis": "x",
         "y": [
          35.89999999999997
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "<b>%{hovertext}</b><br><br>method=%{x}<br>best_scorer=%{y}<br>num_top_appearance=%{marker.size}<extra></extra>",
         "hovertext": [
          "langchain_recursive_mmr"
         ],
         "legendgroup": "langchain_recursive_mmr",
         "marker": {
          "color": "#00CC96",
          "line": {
           "color": "darkgrey",
           "width": 3
          },
          "size": [
           9
          ],
          "sizemode": "area",
          "sizeref": 0.0875,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "langchain_recursive_mmr",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "langchain_recursive_mmr"
         ],
         "xaxis": "x",
         "y": [
          32.000000000000014
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "<b>%{hovertext}</b><br><br>method=%{x}<br>best_scorer=%{y}<br>num_top_appearance=%{marker.size}<extra></extra>",
         "hovertext": [
          "llama_index_sentence_retrieval"
         ],
         "legendgroup": "llama_index_sentence_retrieval",
         "marker": {
          "color": "#AB63FA",
          "line": {
           "color": "darkgrey",
           "width": 3
          },
          "size": [
           35
          ],
          "sizemode": "area",
          "sizeref": 0.0875,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "llama_index_sentence_retrieval",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "llama_index_sentence_retrieval"
         ],
         "xaxis": "x",
         "y": [
          34.89999999999998
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "<b>%{hovertext}</b><br><br>method=%{x}<br>best_scorer=%{y}<br>num_top_appearance=%{marker.size}<extra></extra>",
         "hovertext": [
          "llama_index_auto_merging_retrieval"
         ],
         "legendgroup": "llama_index_auto_merging_retrieval",
         "marker": {
          "color": "#FFA15A",
          "line": {
           "color": "darkgrey",
           "width": 3
          },
          "size": [
           8
          ],
          "sizemode": "area",
          "sizeref": 0.0875,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "llama_index_auto_merging_retrieval",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "llama_index_auto_merging_retrieval"
         ],
         "xaxis": "x",
         "y": [
          29.8
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "height": 600,
        "legend": {
         "bgcolor": "lightgrey",
         "bordercolor": "black",
         "borderwidth": 1,
         "font": {
          "color": "black",
          "family": "Arial, sans-serif",
          "size": 16
         },
         "itemsizing": "constant",
         "title": {
          "text": "Methods"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "b": 60,
         "l": 60,
         "r": 60,
         "t": 60
        },
        "paper_bgcolor": "white",
        "plot_bgcolor": "white",
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "black",
          "family": "Arial, sans-serif",
          "size": 24
         },
         "text": "<b>Best RAG scorer<b>",
         "x": 0.5
        },
        "width": 1800,
        "xaxis": {
         "anchor": "y",
         "categoryarray": [
          "langchain_token_mmr",
          "langchain_recursive_similarity",
          "langchain_recursive_mmr",
          "llama_index_sentence_retrieval",
          "llama_index_auto_merging_retrieval"
         ],
         "categoryorder": "array",
         "domain": [
          0,
          1
         ],
         "showgrid": true,
         "tickangle": 45,
         "tickfont": {
          "color": "black",
          "family": "Arial, sans-serif",
          "size": 18
         },
         "title": {
          "font": {
           "size": 24
          },
          "text": "<b>Methods<b>"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightgrey",
         "showgrid": true,
         "tickfont": {
          "color": "black",
          "family": "Arial, sans-serif",
          "size": 16
         },
         "title": {
          "font": {
           "color": "black",
           "family": "Arial, sans-serif",
           "size": 18
          },
          "text": "<b>Scores<b>"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "color_sequence = px.colors.qualitative.Plotly\n",
    "\n",
    "# Create the scatter plot\n",
    "fig = px.scatter(\n",
    "    final_df,\n",
    "    x=\"method\",\n",
    "    y=\"best_scorer\",\n",
    "    size=\"num_top_appearance\",\n",
    "    hover_name=\"method\",\n",
    "    color=\"method\",  # Assign colors based on the 'system' column\n",
    "    color_discrete_sequence=color_sequence,  # Use the defined color sequence\n",
    "    title=\"<b>Best RAG scorer<b>\",\n",
    ")\n",
    "\n",
    "# Customize the layout\n",
    "fig.update_layout(\n",
    "    title_font=dict(family=\"Arial, sans-serif\", size=24, color=\"black\"),\n",
    "    title_x=0.5,  # Center the title\n",
    "    paper_bgcolor=\"white\",  # Background color for the outer area\n",
    "    plot_bgcolor=\"white\",  # Background color for the plot area\n",
    "    xaxis=dict(\n",
    "        title=\"<b>Methods<b>\",\n",
    "        title_font=dict(size=24),\n",
    "        tickangle=45,  # Rotate labels\n",
    "        tickfont=dict(family=\"Arial, sans-serif\", size=18, color=\"black\"),\n",
    "        showgrid=True,  # Hide gridlines\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title=\"<b>Scores<b>\",\n",
    "        title_font=dict(family=\"Arial, sans-serif\", size=18, color=\"black\"),\n",
    "        tickfont=dict(family=\"Arial, sans-serif\", size=16, color=\"black\"),\n",
    "        showgrid=True,  # Show gridlines\n",
    "        gridcolor=\"lightgrey\",  # Gridline color\n",
    "    ),\n",
    "    legend=dict(\n",
    "        title=\"Methods\",\n",
    "        font=dict(\n",
    "            family=\"Arial, sans-serif\",\n",
    "            size=16,\n",
    "            color=\"black\",\n",
    "        ),\n",
    "        bgcolor=\"lightgrey\",  # Background color for the legend\n",
    "        bordercolor=\"black\",  # Border color for the legend\n",
    "        borderwidth=1,\n",
    "    ),\n",
    "    margin=dict(l=60, r=60, t=60, b=60),  # Adjust margins to fit labels\n",
    "    width=1800,  # Width of the entire plot image\n",
    "    height=600,  # Height of the entire plot image\n",
    ")\n",
    "\n",
    "# Customize marker appearance\n",
    "fig.update_traces(\n",
    "    marker=dict(line=dict(width=3, color=\"darkgrey\")),  # Border line for markers\n",
    "    selector=dict(mode=\"markers\"),\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AR-RT-LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
